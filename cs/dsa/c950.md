# C950 Data Structures and Algorithms 2

## 2 - Algorithm analysis

### 2.1 Relation between data structures and algorithms

- Algorithmns to implement operations (i.e. insert, remove, etc) performed on data structure are specific to each data structure
  - Appending an item to a linked list requires a different algorithm than appending an item to an array

- Algorithms utilize data structures to store and organize data during algorithm execution

### 2.2 Constant time operations

**constant time operation**
- operation that for a given processor, always operates in the same amount of time, regardless of input values
- algorithm analysis describes runtime int terms of constant time operation rather than time since execution time can be affected by processor
- Multiple constant time operations can be collectively be considered as 1 constant time operations

**identifying constant time operations**
- Common constant time operations
  - Additions, substractions, multiplication, and division of fixed size numerical values
    - although these operations differ in execution time, they take the same amount of time (constant) regardless of the operand values   
  - variable assignment
  - comparison of 2 fixed size data values
  - array read/write at a particular index
  - A loop with constant number of iterations
    - a loop with variable number of iterations is not a constant time operation since it can take longer or shorter depending on the number of iterations
<details>
  <summary>Constant time vs non-constant time operations</summary>

  ![image](https://user-images.githubusercontent.com/14286113/173057613-c9a9b758-e400-44c3-9bac-276818a3b087.png)
</details>
  
### 2.3 Algorithm Efficiency

**algorithm efficiency**
- measured by algorithm's computational complexity (amount of resources used)
- Resources: runtime and memory usage
  - long runtimes and high memory usage means algorithm is inefficient 

**runtime complexity**
- _T(N)_ function that represents the number of constant time operations performed by algorithm on an input of size `N`
- depends on input data so runtime complexity is evaluated according to best and worst case scenarios

**Best/worst case**
- describes contents of algorithm's input data
  - input data must be variable 
- best case: scenario where the algorithm does the min possible number of operations
- worst case: scenario where the algorithm does max possible number of operations
  -  ex: searching for an element that does not exist in an array
<details>
  <summary>Ex: Linear search best and worst cases</summary>

  ![image](https://user-images.githubusercontent.com/14286113/173144424-ad068856-beda-457e-9a5a-1a1697c12143.png)

</details>

**Space complexity**
- _S(N)_ function that represents the number of fixed-size memory units used by the algorithm for an input of size N
  - includes input data + additional memory for things like loop counters and list pointers
- Auxilary space complexity: space complexity without input data
  - usually is constant since _S(N)_ is dependent on input data (_N_) but auxilary space complexity isn't
<details>
  <summary>Ex: space complexity</summary>
  
  - ![image](https://user-images.githubusercontent.com/14286113/173176867-5778f7ab-b78b-4055-95e1-c7cf1d44427c.png)
</details>

### 2.4 Growth of functions and complexity

**bounds**
- lower bound: _f(N)_ that is less than the best case _T(N)_ for all values of `N >= 1`
  - an algorithms best case runtime complexity is always a lower bound for the algorithm
- upper bound: _f(N)_ that is greater than the worst case _T(N)_ for all values of `N >= 1`
  - an algorithms worst case runtime complexity is always a upper bound for the algorithm
- bounds are used to collectively bound all runtime complexities for an algorithm, from min to max complexities
- Example:  Best-case Runtime - `T(N) = 7N + 36` & Worst-case Runtime - `T(N) = 3N^2 + 10N + 17`
  - lower bound: `f(N) = 7N`
  - upper bound: `f(N) = 30N^2`
<details>
  <summary>Upper and lower bound graph</summary>

  ![image](https://user-images.githubusercontent.com/14286113/173181760-c657c46c-a4c8-44ee-bcbf-c9613df19409.png)

</details>

**Growth rates and asymptotic notations**
- asymptotic notation: classification of runtime complexity that uses functions that indicate only the growth rate of a bounding function
- its usually a bounding function where the constants are factored out
<details>
  <summary>Notation</summary>
  
  ![image](https://user-images.githubusercontent.com/14286113/173181967-ea036b62-e71b-4014-a4dd-d9d6aa1bb67a.png)
</details>

<details>
  <summary>Finding growth rates</summary>

![image](https://user-images.githubusercontent.com/14286113/173182098-f9a026d7-c764-45f8-a97a-493564bea0cd.png)

</details>


### 2.5 O Notation

**Big O notation**
- mathematical way of describing how a runtime complexity (function) behaves in relation to the input size
- different functions can have the same growth rate and therefore, same Big O notation
- growth rate is determined by the highest order term of the function (the highest exponent) while other terms are discarded/ ignored
  - constants are omitted
<details>
  <summary>Composite function Big O rules</summary>
  
  ![image](https://user-images.githubusercontent.com/14286113/173187438-306da1b5-f5ee-4725-83b4-cb12c8ab18aa.png)  
</details>

<details>
  <summary>Examples</summary>
  
  ![image](https://user-images.githubusercontent.com/14286113/173187615-eae478d3-c8f5-40d5-8317-5f6b10dcc037.png)
</details>

**Running Growth Rates**

- Runtime complexity for algorithms becomes important for large input sizes as the difference in computation time can vary greatly with different growth rates

<details>
  <summary>Growth Rate times</summary>
  
  ![image](https://user-images.githubusercontent.com/14286113/173188022-ac4302b5-cb6f-4550-beb6-0851e1e600c7.png)
</details>

**Common Big O complexities**

<details> 
  <summary>Examples</summary>
  
  ![image](https://user-images.githubusercontent.com/14286113/173188260-a341b964-4d12-40cb-9a1b-428beb530929.png)
  
  ![image](https://user-images.githubusercontent.com/14286113/173188358-b53a0214-fa39-4a66-828f-6de894bd45e8.png)
</details>

### 2.6 Algorithm analysis

**Worst-case runtime**
- ...of an algorithm is the runtime complexity for an input that results in the longest execution time
- often the main focus in algorithmn analysis

**Algorithm analysis**
- how runtime of an algorithm scales as the input size increases 
1. determine number of operations algorithm executes for a specific input size N
2/ determine the big-O notation based on the above runtime complexity function
<details>
  <summary>Algorithm Analysis Example</summary>
  
  ![image](https://user-images.githubusercontent.com/14286113/173208717-0602a84c-cc69-42f3-8b08-19e4d25eee97.png)
  ![image](https://user-images.githubusercontent.com/14286113/173209059-c4c7c4b4-ee7c-4797-8655-ee2b94f0d4ce.png)
  [Simplified runtime analysis when O(1)](https://user-images.githubusercontent.com/14286113/173209134-60db40ad-693c-45fe-96cf-df44431b9b3d.png)
</details>

**How to analyze**
- _loops_
  - runtime complexity function analysis:
    - initial assignment is always executed once 
    - 2 operations per iteration for increment and comparison expressions + operations for code inside for loop block
  - big O analysis:
    - _O(N)_ for traditional for-loop that do not have nested loops, function calls, or modify the iterator in the loop
    - if for-loop is executed constant number of times instead of variable (as in i<N), then it is effectively O(1) 
- _loops where iterator is modified_
  - runtime complexity function analysis:
    - `Constant time operations * (N/x)` where `x` is the number iteration is decreased by 
      - ex: 5N/2 for 5 operations that execute when i is even number (N/2)
  - big O analysis: N/x
    - ex: N/2 for when i % 2 == 0 (even number)   
- _logN_: if iterations are decreased by some fraction each iteration, then it is considered to be logN
- _Counting constant time operations_: 
  - Ex: if/else statements, comparisons, assignments, math calculations, etc that are done 1 times (instead of N times)   
  - runtime complexity function analysis: add up the number of operations performed by each statement (?)
  - big O analysis: any statement or constant number of statements, runtime complexity is considered to be _O(1)_ or _1_
      - ex:, if there are 3 operations each loop iteration...then it can be considered to be `N` operations instead of `3N`
      - if there are 20 operations before and after a loop, then these can be collectively considered to be effectively `1` operation
  <details>
    <summary>- Constant time operations examples</summary>

    ![image](https://user-images.githubusercontent.com/14286113/173209458-90a2f800-9f29-4024-9f6f-32c41d65edab.png)
  </details>
- _Nested loops_
  - For one nested loop, big-o will be _O(N^2)_
  - For X nested loops, big-O: _O(N^x)_
  <details>
  <summary>Nested loop analysis</summary>
  
   ![image](https://user-images.githubusercontent.com/14286113/173209687-780592f4-5f93-4707-8fed-681e6d8d36a5.png)
  </details>

### 2.7 Complexity Classes

_..._
